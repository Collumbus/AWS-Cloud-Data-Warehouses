{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch_a_Redshift_Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Launch a Redshift Cluster\n",
       "\n",
       "**WARNING:** The cluster that you are about to launch will be live, and you will be charged the standard Amazon Redshift usage fees for the cluster until you delete it. **Make sure to delete your cluster each time you're finished working to avoid large, unexpected costs for yourself.** You can always launch a new cluster, so don't leave your Redshift cluster running overnight or throughout the week if you don't need to.\n",
       "\n",
       "##### Getting Started\n",
       "\n",
       "* Sign in to the AWS Management Console and open the Amazon Redshift console https://console.aws.amazon.com/redshift/\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Navigate to a new service](img/8.1.png)|\n",
       "|:--:|\n",
       "|*Navigate to a new service*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "* On the Amazon Redshift Dashboard, choose **Create cluster**. It will launch the Create cluster wizard.\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "|![Amazon Redshift dashboard](img/8.2.png)|\n",
       "|:--:|\n",
       "|*Amazon Redshift dashboard*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "##### Prerequisite\n",
       "\n",
       "1. **A cluster subnet group**\n",
       "\n",
       "      A [cluster subnet group](https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-cluster-subnet-groups.html) is logical group of subnets in your existing VPC in which yu want to create your Redshift cluster.\n",
       "\n",
       "      * Within the Redshift service, and go to **Configurations â†’ Subnet groups**.\n",
       "      * Provide the subnet group name of your choice, choose the VPC, and add all subnets of the VPC to the current cluster subnet group. See the snapshots below.\n",
       "      * Click on the \"Create\" button, and wait until the status shows \"Complete\".\n",
       "  \n",
       "|![Amazon Redshift â†’ Configurations â†’ Subnet groups](img/8.3.png)|\n",
       "|:--:|\n",
       "|*Amazon Redshift â†’ Configurations â†’ Subnet groups*|\n",
       "\n",
       "|![Amazon Redshift â†’ Configurations â†’ Subnet groups](img/8.4.png)|\n",
       "|:--:|\n",
       "|*Create a cluster subnet group from a default VPC*|\n",
       "\n",
       "|![Amazon Redshift â†’ Configurations â†’ Subnet groups](img/8.5.png)|\n",
       "|:--:|\n",
       "|*Success message - Cluster subnet group*|\n",
       "\n",
       "2. An IAM role, say **myRedshiftRole**, with *Redshift - Customizable* use case and `AmazonS3ReadOnlyAccess` policy attached.\n",
       "\n",
       "3. A Security group, say **redshift_security_group**, that allows inbound traffic (from anywhere) on the port 5439 and outbound traffic to anywhere.\n",
       "\n",
       "##### Cluster Creation\n",
       "\n",
       "1. **Basic configuration**\n",
       "    Provide a unique identifier, such as `redshift-cluster-1`, and choose the **Production** option because we want to change some of the default configuration.\n",
       "\n",
       "    For the cluster size, choose 1 node of `dc2.large` hardware type. It is a high performance node with:\n",
       "    * 2 vCPUs\n",
       "    * fixed 160 GB SSD storage capacity\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "|![Cluster's basic configuration](img/8.6.png)|\n",
       "|:--:|\n",
       "|*Cluster's basic configuration*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "2. **Sample data**\n",
       "    Select the checkbox to load the sample data to your Redshift cluster. It will load a sample dataset tickitDB with a sample database called TICKIT.\n",
       "\n",
       "|![Load sample data to your Redshift cluster](img/8.7.png)|\n",
       "|:--:|\n",
       "|*Load sample data to your Redshift cluster*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "3. **Database configurations**\n",
       "    Provide the username and password for the database.\n",
       "\n",
       "![table 1](img/8.8.png)\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "**Please note:** We **strongly advise** you to keep these passwords closely guarded, including not putting them in your GitHub public repo, etc. \n",
       "\n",
       "|![Database configurations](img/8.9.png)|\n",
       "|:--:|\n",
       "|*Database configurations*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "4. **Cluster permissions**\n",
       "    Choose the IAM role created earlier, *myRedshiftRole*, from the drop-down and click on the *Associate IAM role button*.\n",
       "    \n",
       "|![Cluster permissions. Associate the custom IAM role. ](img/8.10.png)|\n",
       "|:--:|\n",
       "|*Cluster permissions. Associate the custom IAM role.*|\n",
       "    \n",
       "<br />\n",
       "\n",
       "\n",
       "5. **Additional configurations**\n",
       "    * Toggle the button to turn off the \"use defaults\" feature,\n",
       "    * Network and security - Choose the following values:\n",
       "![table 2](img/8.11.png)\n",
       "\n",
       "|![Do not use defaults in the Additional configurations](img/8.12.png)|\n",
       "|:--:|\n",
       "|*Do not use defaults in the Additional configurations*|\n",
       "\n",
       "|![Network and security section](img/8.13.png)|\n",
       "|:--:|\n",
       "|*Network and security section*|\n",
       "    \n",
       "<br />\n",
       "\n",
       "\n",
       "* **Additional database configurations:** The default database name and open port would be:\n",
       "![table 3](img/8.14.png)\n",
       "\n",
       "|![Additional database configurations](img/8.15.png)|\n",
       "|:--:|\n",
       "|*Additional database configurations*|\n",
       "    \n",
       "<br />\n",
       "\n",
       "\n",
       "6. Leave the remaining configurations as default. Review your Cluster configurations and click on the **Create cluster** button at the bottom. It will take a few minutes to create the cluster.\n",
       "\n",
       "7. Click on the **Clusters** menu item from the left navigation pane, and look at the cluster that you just launched. Make sure that the **Status** is **Available** before you try to connect to the database later. You can expect this to take 5-10 minutes.\n",
       "\n",
       "|![If the status shows \"Available\", the Cluster is ready to be connected](img/8.16.png)|\n",
       "|:--:|\n",
       "|*If the status shows \"Available\", the Cluster is ready to be connected*|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"0-Launch_a_Redshift_Cluster.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create an IAM User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Create an IAM User\n",
       "\n",
       "Here, you'll create an IAM user that you will use to access your Redshift cluster.\n",
       "\n",
       "1. Navigate to the [IAM console](https://console.aws.amazon.com/iam/). In the left navigation pane, choose **Users**, and click on the **Add User** button. It will launch a new wizard.\n",
       "<br />\n",
       "\n",
       "|![IAM Users dashboard](img/9.1.png)|\n",
       "|:--:|\n",
       "|*IAM Users dashboard*|\n",
       "\n",
       "<br />\n",
       "\n",
       "2.  **Set user details**\n",
       "    \n",
       "    Enter a name for your user , say airflow_redshift_user, and choose Programmatic access. Then click on the Next: Permissions button.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Create IAM users â†’ Set user details](img/9.2.png)|\n",
       "|:--:|\n",
       "|*Create IAM users â†’ Set user details*|\n",
       "\n",
       "<br />\n",
       "\n",
       "3.  **Set permissions**\n",
       "\n",
       "    Choose Attach existing policies directly option.\n",
       "    * Search for redshift and select AmazonRedshiftFullAccess.\n",
       "    * Then, search for S3 and select AmazonS3ReadOnlyAccess.\n",
       "  After selecting both policies, choose Next: Tags. Skip this page and choose Next: Review.\n",
       "  \n",
       "<br />\n",
       "\n",
       "|![Create IAM user â†’ Set permissions â†’ Select AmazonRedshiftFullAccess](img/9.3.png)|\n",
       "|:--:|\n",
       "|*Create IAM user â†’ Set permissions â†’ Select AmazonRedshiftFullAccess*|\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Create IAM user â†’ Set permissions â†’ Select AmazonS3ReadOnlyAccess](img/9.4.png)|\n",
       "|:--:|\n",
       "|*Create IAM user â†’ Set permissions â†’ Select AmazonS3ReadOnlyAccess*|\n",
       "\n",
       "<br />\n",
       "\n",
       "4. **Review** your choices and finally click on the **Create user** button.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Review the new IAM user details](img/9.5.png)|\n",
       "|:--:|\n",
       "|*Review the new IAM user details*|\n",
       "\n",
       "<br />\n",
       "\n",
       "5. **Save your credentials!**\n",
       "    \n",
       "    This is the only time you can view or download these credentials on AWS. Choose **Download .csv** to download these credentials and then save this file to a safe location. You'll need to copy and paste this **Access key ID** and **Secret access key** in the next step.\n",
       "\n",
       "We strongly advise you to keep this **Access key ID** and **Secret access key** closely guarded, including not putting them in a GitHub public repo, etc.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![User created successfully.](img/9.6.png)|\n",
       "|:--:|\n",
       "|*User created successfully.*<br />\n",
       "***Copy the Access key Is and Secret access key.***|\n",
       " \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"1-Create_an_IAM_User.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create an IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Create an IAM Role\n",
       "\n",
       "Here, you'll create an IAM role that you will later attach to your Redshift cluster to enable your cluster to load data from Amazon S3 buckets. Read more about IAM roles and Redshift [here](https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-create-an-iam-role.html).\n",
       "\n",
       "   1. Once you have signed into the AWS management console, navigate to the [IAM service dashboard](https://console.aws.amazon.com/iam/).\n",
       "   2. In the left navigation pane, choose **Roles**.\n",
       "   3. Choose **Create role**.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![IAM Roles dashbaord](img/6.1.png)|\n",
       "|:--:|\n",
       "|*IAM Roles dashbaord*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   4. In the **AWS Service** group as the trusted entity, and choose **Redshift** service.\n",
       "   5. Under **Select your use case**, choose **Redshift - Customizable**, and then **Next: Permissions**.\n",
       "\n",
       "<br />\n",
       "\n",
       "![fig1](img/6.2.png)\n",
       "\n",
       "|![Select Redshift service, and Redshift - Customizable use case](img/6.3.png)|\n",
       "|:--:|\n",
       "|*Select Redshift service, and Redshift - Customizable use case*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "   6. On the **Attach permissions policies page**, search for and select the **AmazonS3ReadOnlyAccess policy**, and then click on the **Next: Tags button**.\n",
       "   7. Tags are optional. Click on the **Next: Review** button.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Select a policy to attach to the new role](img/6.4.png)|\n",
       "|:--:|\n",
       "|*Select a policy to attach to the new role*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "   8. For **Role name**, enter ```myRedshiftRole```, and then choose **Create Role**.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Provide role name and description](img/6.5.png)|\n",
       "|:--:|\n",
       "|*Provide role name and description*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "\n",
       "   9. You will see a success message when the new role will be created.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Role created successfully](img/6.6.png)|\n",
       "|:--:|\n",
       "|*Role created successfully*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   That's great! On the next page, you'll learn to **attach this role to a new/existing cluster**.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"Create_an_IAM_Role.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Security Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Create Security Group\n",
       "\n",
       "Here, you'll create a security group you will later use to authorize access to your Redshift cluster.\n",
       "\n",
       "   A security group will act as firewall rules for your Redshift cluster to control inbound and outbound traffic.\n",
       "\n",
       "   1. Navigate to the [EC2 service](https://console.aws.amazon.com/ec2)\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Navigate to any service](img/7.1.png)|\n",
       "|:--:|\n",
       "|*Navigate to any service*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   2. Under **Network and Security** in the left navigation pane, select **Security Groups**. Click the **Create Security Group** button to launch a wizard.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Create a new security group](img/7.2.png)|\n",
       "|:--:|\n",
       "|*Create a new security group*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   3. In the Create security group wizard, enter the basic details.\n",
       "\n",
       "<br />\n",
       "\n",
       "![table1](img/7.3.png)\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Create a default VPC, if not available already](img/7.4.png)|\n",
       "|:--:|\n",
       "|*Create a default VPC, if not available already*|\n",
       "\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Info about a default VPC](img/7.5.png)|\n",
       "|:--:|\n",
       "|*Info about a default VPC*|\n",
       "\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Basic details](img/7.6.png)|\n",
       "|:--:|\n",
       "|*Basic details*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   4. In the Inbound rules section, click on **Add Rule** and enter the following values:\n",
       "\n",
       "<br />\n",
       "\n",
       "![table2](img/7.7.png)\n",
       "\n",
       "<br />\n",
       "\n",
       "   **Important: Using ```0.0.0.0/0``` is not recommended for anything other than demonstration purposes because it allows access from any computer on the internet**. In a real environment, you would create inbound rules based on your own network settings.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Inbound rules](img/7.8.png)|\n",
       "|:--:|\n",
       "|*Inbound rules*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   5. Outbound rules allow traffic to anywhere by default.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Outbound rules](img/7.9.png)|\n",
       "|:--:|\n",
       "|*Outbound rules*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "   6. Click on the Create security group button at the bottom. You will see a success message.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Details of a security group](img/7.10.png)|\n",
       "|:--:|\n",
       "|*Details of a security group*|\n",
       "\n",
       "<br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"3-Create_Security_Group.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Delete a Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Delete a Redshift Cluster\n",
       "\n",
       "Make sure to delete your cluster each time you're finished working to avoid large, unexpected costs. You can always launch a new cluster, so don't leave it running overnight or throughout the week if you don't need to.\n",
       "\n",
       "Steps to delete a cluster are:\n",
       "\n",
       "   1. On the **Clusters** page of your Amazon Redshift console, click on the check-box next to your cluster name. Then click on the **Actions** drop-down button on top â†’ select **Delete**.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Delete a cluster](img/10.1.png)|\n",
       "|:--:|\n",
       "|*Delete a cluster*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "   2. You can choose to not **Create final snapshot**, and click on the **Delete cluster** button.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Prompt before deleting the cluster](img/10.2.png)|\n",
       "|:--:|\n",
       "|*Prompt before deleting the cluster*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   3. Your cluster will change it's status to **deleting**, and then disappear from your Cluster list once it's finished deleting. You'll no longer be charged for this cluster.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"4-Delete_a_Redshift_Cluster.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# S3 Create a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's learn how to create a bucket in [Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/gsg/GetStartedWithS3.html), and view a few properties of an existing bucket.\n",
       "\n",
       "#### Create a Bucket\n",
       "\n",
       "   1. Navigate to the (S3 dashboard)[https://classroom.udacity.com/nanodegrees/nd027/parts/bb5828e0-2c01-4632-b79a-472e5f9a5d1d/modules/4bd17bdc-8013-449d-b334-5c2c75d39a63/lessons/f27059b5-5894-4f47-9fe1-d4d413c30cf6/concepts/console.aws.amazon.com/s3/home], and click on the **Create bucket** button. It will launch a new wizard.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![S3 service â†’ Buckets dashboard](img/11.1.png)|\n",
       "|:--:|\n",
       "|*S3 service â†’ Buckets dashboard.*<br />\n",
       "*View all of the S3 buckets in your account*<br />\n",
       "*(S3 is a global service, not a region-specific).*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "\n",
       "We create a bucket first, and later we upload files and folders to it.\n",
       "\n",
       "   2. **General configuration**\n",
       "    Provide the bucket-name and the region where you want to locate the bucket. The bucket name must be unique worldwide, and must not contain spaces or uppercase letters.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Create a bucket - Provide general details](img/11.2.png)|\n",
       "|:--:|\n",
       "|*Create a bucket - Provide general details*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "\n",
       "   3. **Public Access settings**\n",
       "    You can choose public visibility. Let's uncheck the Block all public access option.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Create a bucket - Make it public](img/11.3.png)|\n",
       "|:--:|\n",
       "|*Create a bucket - Make it public*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   4. **Bucket Versioning and Encryption**\n",
       "        * Bucket Versioning - Keep it disabled.\n",
       "        * Encryption - If enabled, it will encrypt the files being stored in the bucket.\n",
       "        * Object Lock - If enables, it will prevent the files in the bucket from being deleted or modified.\n",
       "\n",
       "   3. **Public Access settings**\n",
       "    You can choose public visibility. Let's uncheck the Block all public access option.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Create a bucket - Provide additional details](img/11.4.png)|\n",
       "|:--:|\n",
       "|*Create a bucket - Provide additional details*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "In the snapshots above, we have created a public bucket. Let's see **how to upload files and folders to the bucket**, and configure additional settings.\n",
       "\n",
       "##### Upload File/Folders to the Bucket\n",
       "\n",
       "From the (S3 dashboard)[https://classroom.udacity.com/nanodegrees/nd027/parts/bb5828e0-2c01-4632-b79a-472e5f9a5d1d/modules/4bd17bdc-8013-449d-b334-5c2c75d39a63/lessons/f27059b5-5894-4f47-9fe1-d4d413c30cf6/concepts/console.aws.amazon.com/s3/home], click on the name of the bucket you have created in the step above.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Details of an existing bucket. Upload files/folders to this bucket.](img/11.5.png)|\n",
       "|:--:|\n",
       "|*Details of an existing bucket. Upload files/folders to this bucket.*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "In the snapshot above, it shows that the bucket is in the Region: ```US East (Ohio) us-east-2```, and it has a unique Amazon resource name (ARN): ```arn:aws:s3:::mtvbucket```. You can view more details of the bucket, in the tabs next to the bucket overview: **Objects, Properties, Permissions, Metrics, Management**, and **Access points**. Leet's upload a sample file to the bucket:\n",
       "\n",
       "   1. Click on the **Upload** button to upload files and folders into the current bucket. In the snapshot below, we have uploaded a **Sample.txt** file.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![A sample file in the bucket](img/11.6.png)|\n",
       "|:--:|\n",
       "|*A sample file in the bucket*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "   2. Click on the file name to view the file-specific details, as shown below.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Details of an individual file (object)](img/11.7.png)|\n",
       "|:--:|\n",
       "|*Details of an individual file (object)*|\n",
       "\n",
       "<br />\n",
       "\n",
       "#### Details of an Existing Bucket\n",
       "**1. Properties**\n",
       "\n",
       "There are several properties that you can set for S3 buckets, such as:\n",
       "\n",
       "   * Bucket Versioning - Allows you to keep multiple versions of an object in the same bucket.\n",
       "   * Static website hosting - Mark if the bucket is used to host a website. S3 is a very cost-effective and cheap solution for serving up static web content.\n",
       "   * Requester pays - Make the requester pays for requests and data transfer costs.\n",
       "   * Server access logging - Log requests for access to your bucket.\n",
       "   * **Permissions**\n",
       "\n",
       "It shows who has access to the S3 bucket, and who has access to the data within the bucket. In the example snapshots above, the bucket is public, meaning anyone can access it. Here, we can write an access policy (in JSON format) to provides access to the objects stored in the bucket.\n",
       "\n",
       "**2. Metrics**\n",
       "\n",
       "View the metrics for usage, request, and data transfer activity within your bucket, such as, total bucket size, total number of objects, and storage class analysis.\n",
       "\n",
       "**3. Management**\n",
       "\n",
       "It allows you to create life cycle rules to help manage your objects. It includes rules such as transitioning objects to another storage class, archiving them, or deleting them after a specified period of time.\n",
       "\n",
       "**4. Access points**\n",
       "\n",
       "Here, you can create access endpoints for sharing the bucket at scale. Using an endpoint, you can perform all regular operations on the bucket.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"5-S3_Create_a_Bucket.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# RDS Create PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to AWS:\n",
       "\n",
       "   [Amazon RDS](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html) is a relational database service that manages common database administration tasks, resizes automatically, and is cost-friendly.\n",
       "\n",
       "Let's see how to create a PostgresSQL database, and view the details of an existing database.\n",
       "\n",
       "#### RDS Dashboard\n",
       "\n",
       "Navigate to the [RDS dashboard](https://console.aws.amazon.com/rds/home). It shows the database-resources summary, such as the count of database instances, the health of the database service, reserved instances, snapshots. You can also view the portion of the allocated storage. You can launch the **Create database** wizard from here.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![RDS dashboard](img/12.1.png)|\n",
       "|:--:|\n",
       "|*RDS dashboard*|\n",
       "\n",
       "<br />\n",
       "\n",
       "#### Create a PostgreSQL DB\n",
       "\n",
       "If you haven't launched already, choose the **Databases** menu item on the left navigation pane, and click on the **Create Database** button.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Amazon RDS service â†’ Databases dashboard](img/12.2.png)|\n",
       "|:--:|\n",
       "|*Amazon RDS service â†’ Databases dashboard*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   1. **Choose a database creation method**\n",
       "   \n",
       "   AWS provides two options to choose from:\n",
       "       * Standard create - You have set all of the configuration options, including ones for availability, security, backups, and maintenance.\n",
       "       * Easy create - You use the industry best-practice configurations. All configuration options, except the Encryption and VPC details, can be changed after the database is created.\n",
       "\n",
       "   The steps below will show you the **Standard create** fields/options.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Choose a database creation method](img/12.3.png)|\n",
       "|:--:|\n",
       "|*Choose a database creation method*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   2. **Engine options**\n",
       "   \n",
       "   Select **PostgreSQL** option. It will pick up the latest stable release by default, though you can select a version of your choice as well.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Engine options](img/12.4.png)|\n",
       "|:--:|\n",
       "|*Engine options*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   3. **Templates**\n",
       "   \n",
       "   Use either the **RDS Free Tier** or **Dev/Test** template. On free-tier resources, you can develop and test applications to gain hands-on experience with Amazon RDS.\n",
       "   \n",
       "   The free tier will offer you 750 hrs of Amazon RDS in a Single-AZ ```db.t2.micro``` Instance, 20 GB of General Purpose Storage (SSD), and 20 GB for automated backup storage and any user-initiated DB Snapshots.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Templates](img/12.5.png)|\n",
       "|:--:|\n",
       "|*Templates*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   4. **Settings**\n",
       "   \n",
       "   Provide a *DB instance identifier*, such as *postgreSQL-test*, and master credentials (username and a password). Take note of this password, as it is useful for future steps. You will be able to find this password and change it later in the console.\n",
       "\n",
       "   Alternatively, you can auto-generate the password. In this case, AWS will show you the password once you create the database successfully.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Settings](img/12.6.png)|\n",
       "|:--:|\n",
       "|*Settings*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   5. **DB instance class**\n",
       "   \n",
       "   The options here present the options for processing power and memory requirements. Since we have selected the Free tier option above, the only available option is ```db.t2.micro```, which has 1 vCPU, and 1 GiB RAM.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![DB instance class](img/12.7.png)|\n",
       "|:--:|\n",
       "|*DB instance class*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "   8. **Storage and Availability & durability**\n",
       "   \n",
       "   Choose the default values for both these sections. It will offer you 20 GiB SSD storage, expandable up to 1000 GiB, by default. For *Availability & durability* section, it will not offer us to have a Multi-AZ deployment.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Storage and Availability & durability](img/12.8.png)|\n",
       "|:--:|\n",
       "|*Storage and Availability & durability*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   7. **Connectivity**\n",
       "   \n",
       "   Choose/ensure the following values:\n",
       "\n",
       "<br />\n",
       "\n",
       "![table1](img/12.9.png)\n",
       "\n",
       "<br />\n",
       "\n",
       "   **Leave the values default for the Database authentication section.**\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Connectivity](img/12.10.png)|\n",
       "|:--:|\n",
       "|*Connectivity*|\n",
       "\n",
       "<br />\n",
       "\n",
       "   8. **Additional configuration**\n",
       "   \n",
       "   * Provide the database name. If you do not specify a database name, Amazon RDS will not create a database.\n",
       "   * In the *Backup* section and select *1 day*, since this is for demonstration purposes.\n",
       "   * Leave the default values for the rest and click on the **Create database** button on the bottom right.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Additional configuration](img/12.11.png)|\n",
       "|:--:|\n",
       "|*Additional configuration*|\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Additional configuration](img/12.12.png)|\n",
       "|:--:|\n",
       "|*Additional configuration*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "   9. **Success**\n",
       "   \n",
       "   You should land on a confirmation page. It will take a few minutes to launch the database. Wait a few minutes for the status to change to **Available**.\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Additional configuration](img/12.13.png)|\n",
       "|:--:|\n",
       "|*Additional configuration*|\n",
       "\n",
       "<br />\n",
       "\n",
       "<br />\n",
       "\n",
       "|![Wait a few minutes for the status to change to **Available**.](img/12.14.png)|\n",
       "|:--:|\n",
       "|*Wait a few minutes for the status to change to **Available**.*|\n",
       "\n",
       "<br />\n",
       "\n",
       "\n",
       "For each database in the list above, you can see the Region and availability zone it's running in, the size, and the status that it's up and running. You can also see the percentage utilization of the underlying CPU.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"6-RDS_Create_PostgreSQL_Database.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Launch Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Launching a Redshift Cluster in the AWS Console\n",
       "\n",
       "   * Follow the instructions below to create a Redshift cluster\n",
       "   * Use the query editor to create a table and insert data\n",
       "   * Delete the cluster\n",
       "\n",
       "Note: The steps below were introduced in lesson 2. You can use the IAM role and security group created in the last lesson.\n",
       "\n",
       "### Launch a Redshift Cluster\n",
       "\n",
       "**WARNING:** The cluster that you are about to launch will be live, and you will be charged the standard Amazon Redshift usage fees for the cluster until you delete it. **Make sure to delete your cluster each time you're finished working to avoid large, unexpected costs.** Instructions on deleting your cluster are included on the last page. You can always launch a new cluster, so don't leave your Redshift cluster running overnight or throughout the week if you don't need to.\n",
       "\n",
       "   1. Open AWS Console by clicking on the ```Launch AWS Gateway``` button followed by ```Open AWS Console```.\n",
       "   2. Search and select ```Redshift``` in the AWS Services search bar. This will open the Amazon Redshift Dashboard.\n",
       "   3. On the Amazon Redshift Dashboard, choose **Create cluster**.\n",
       "\n",
       "![Fig 1](img/15.1.png)\n",
       "\n",
       "\n",
       "   4. On the Cluster details page, enter the following values and then choose Continue:\n",
       "       * **Cluster identifier:** Enter ```redshift-cluster```.\n",
       "       * **Database name:** Enter ```dev```.\n",
       "       * **Database port:** Enter ```5439```.\n",
       "       * **Master user name:** Enter ```awsuser```.\n",
       "       * **Master user password** and **Confirm password:** Enter a password for the master user account.\n",
       "\n",
       "![Fig 2](img/15.2.png)\n",
       "\n",
       "   5. On the Node Configuration page, accept the default values and choose Continue.\n",
       "\n",
       "![Fig 3](img/15.3.png)\n",
       "\n",
       "   6. On the Additional Configuration page, enter the following values:\n",
       "        **VPC security groups:** redshift_security_group\n",
       "        **Available IAM roles:** myRedshiftRole\n",
       "\n",
       "   Choose **Continue**.\n",
       "\n",
       "![Fig 4](img/15.4.png)\n",
       "\n",
       "   7. Review your Cluster configuration and choose Launch cluster.\n",
       "\n",
       "![Fig 5](img/15.5.png)\n",
       "\n",
       "   8. A confirmation page will appear and the cluster will take a few minutes to finish. Choose **Clusters** in the left navigation pane to return to the list of clusters.\n",
       "\n",
       "![Fig 6](img/15.6.png)\n",
       "\n",
       "   9. On the Clusters page, look at the cluster that you just launched and review the **Cluster Status** information. Make sure that the **Cluster Status** is **available** and the **Database Health** is **healthy** before you try to connect to the database later. You can expect this to take 5-10 minutes.\n",
       "\n",
       "![Fig 7](img/15.7.png)\n",
       "\n",
       "![Fig 8](img/15.8.png)\n",
       "\n",
       "\n",
       "### Delete a Redshift Cluster\n",
       "\n",
       "Make sure to delete your cluster each time you're finished working to avoid large, unexpected costs. You can always launch a new cluster, so don't leave it running overnight or throughout the week if you don't need to.\n",
       "\n",
       "   1. On the **Clusters** page of your Amazon Redshift console, click on the box next to your cluster to select it, and then click on **Cluster > Delete cluster**.\n",
       "\n",
       "![Fig 9](img/15.9.png)\n",
       "\n",
       "   2. You can choose **No** for **Create snapshot**, check the box that you acknowledge this, and then choose **Delete**.\n",
       "\n",
       "![Fig 10](img/15.10.png)\n",
       "\n",
       "   3. Your cluster will change it's status to **deleting**, and then disappear from your Cluster list once it's finished deleting. You'll no longer be charged for this cluster.\n",
       "![Fig 11](img/15.11.png)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"7-Launch_Redshift_Cluster.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import dateutil.parser\n",
    "\n",
    "headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'token_exact': '4e0d180f-1b29-4012-a78f-2a499585aa59'\n",
    "        }\n",
    "i = 0\n",
    "raw_data = []\n",
    "while True:\n",
    "    response = requests.get(f'https://api.exactsales.com.br/v3/QualificationHistories?$skip={i}&$top=500', headers=headers)\n",
    "\n",
    "    hist = response.json()\n",
    "    for item in hist['value']:\n",
    "        data = item['qualificationDate']\n",
    "        d = dateutil.parser.isoparse(data)\n",
    "        item['qualificationDate'] = d.strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "        del item['questionAnswers']\n",
    "        for j in item['questionAnswers']:\n",
    "            del j['questionId']\n",
    "            for a in j['answers']:\n",
    "                del a['id']\n",
    "\n",
    "    raw_data.extend(hist['value'])\n",
    "\n",
    "    if len(hist['value']) < 500:\n",
    "        break\n",
    "\n",
    "    i = i + 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leadId': 6240304,\n",
       " 'stage': 'Filtro 1',\n",
       " 'score': 'Muito Quente',\n",
       " 'qualificationDate': '2021-12-30 12:43:25:845926',\n",
       " 'questionAnswers': [{'question': 'Você jura de pézinho junto que esse lead foi conferido no ADMIN (company package e companies), Spotter e PipeDrive? ',\n",
       "   'answers': [{'text': 'Não olhei, só vi no Spotter mesmo...'}]},\n",
       "  {'question': 'Você sabe que se tentar avançar o filtro sem conferir, ele vai barrar, né?',\n",
       "   'answers': [{'text': 'Eita! Conferi aqui e está tudo ok! DEIXA EU AGENDAR'}]},\n",
       "  {'question': 'Você acredita ter perfil enterprise? ',\n",
       "   'answers': [{'text': 'Não tem, mas será muito boa!'}]},\n",
       "  {'question': 'Tem vagas em aberto AGORA?',\n",
       "   'answers': [{'text': 'Sim, possui vagas em aberto'}]}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'questionId'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-1e1100188f08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'questionAnswers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'questionId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'questionId'"
     ]
    }
   ],
   "source": [
    "item['questionAnswers'][0]['questionId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343801\n",
      "1086392\n",
      "356752\n",
      "1125143\n",
      "357540\n",
      "1127721\n"
     ]
    }
   ],
   "source": [
    "for i in item['questionAnswers']:\n",
    "    print(i['questionId'])\n",
    "    for a in i['answers']:\n",
    "        print(a['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leadId': 14326741,\n",
       " 'stage': 'Filtro 1',\n",
       " 'score': 'Muito Quente',\n",
       " 'qualificationDate': '2021-12-29 19:38:50:708524',\n",
       " 'questionAnswers': [{'question': 'Você jura de pézinho junto que esse lead foi conferido no ADMIN (company package e companies), Spotter e PipeDrive? ',\n",
       "   'questionId': 343801,\n",
       "   'answers': [{'id': 1086392,\n",
       "     'text': 'Sim! Olhei em tudinho e não é repetido'}]},\n",
       "  {'question': 'Você acredita ter perfil enterprise? ',\n",
       "   'questionId': 356752,\n",
       "   'answers': [{'id': 1125143, 'text': 'Não tem, mas será muito boa!'}]},\n",
       "  {'question': 'Tem vagas em aberto AGORA?',\n",
       "   'questionId': 357540,\n",
       "   'answers': [{'id': 1127721, 'text': 'Sim, possui vagas em aberto'}]}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leadId': 14326741,\n",
       " 'stage': 'Filtro 1',\n",
       " 'score': 'Muito Quente',\n",
       " 'qualificationDate': '2021-12-29 19:38:50:708524',\n",
       " 'questionAnswers': [{'question': 'Você jura de pézinho junto que esse lead foi conferido no ADMIN (company package e companies), Spotter e PipeDrive? ',\n",
       "   'answers': [{'text': 'Sim! Olhei em tudinho e não é repetido'}]},\n",
       "  {'question': 'Você acredita ter perfil enterprise? ',\n",
       "   'answers': [{'text': 'Não tem, mas será muito boa!'}]},\n",
       "  {'question': 'Tem vagas em aberto AGORA?',\n",
       "   'answers': [{'text': 'Sim, possui vagas em aberto'}]}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
